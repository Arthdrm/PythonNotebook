{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":20541,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":17024},{"sourceId":20542,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":17025}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch Sandbox","metadata":{}},{"cell_type":"markdown","source":"## Environment Setup\n","metadata":{}},{"cell_type":"code","source":"# Installing libraries\n!pip install torchinfo","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:47:20.788408Z","iopub.execute_input":"2024-04-02T17:47:20.788746Z","iopub.status.idle":"2024-04-02T17:47:33.855255Z","shell.execute_reply.started":"2024-04-02T17:47:20.788719Z","shell.execute_reply":"2024-04-02T17:47:33.854350Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# General libraries\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# Pytorch Model and training necessities\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torchinfo import summary # For model architecture summary\n\n# Model performance evaluation\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Pytorch tensorboard support\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T17:47:52.552573Z","iopub.execute_input":"2024-04-02T17:47:52.552899Z","iopub.status.idle":"2024-04-02T17:48:11.326679Z","shell.execute_reply.started":"2024-04-02T17:47:52.552874Z","shell.execute_reply":"2024-04-02T17:48:11.325869Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-02 17:48:02.544578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-02 17:48:02.544681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-02 17:48:02.680476: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Experiments","metadata":{}},{"cell_type":"code","source":"# Create some synthetic data\nx = torch.tensor([1.0, 2.0, 3.0, 4.0], requires_grad=True)  # Input feature\ny_true = torch.tensor([2.0, 4.0, 6.0, 8.0])  # True target values\n\n# Define model parameters (weights and bias)\nw = torch.tensor(1.0, requires_grad=True)\nb = torch.tensor(0.0, requires_grad=True)\n\n# Forward pass\ny_pred = w * x + b\n\n# Calculate loss (Mean Squared Error)\nloss = torch.mean((y_pred - y_true)**2)\n\n# Backward pass (Autograd computes gradients automatically)\nloss.backward()\n\n# Gradients are computed\nprint(\"Gradient of w:\", w.grad)\nprint(\"Gradient of b:\", b.grad)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:39:02.652663Z","iopub.execute_input":"2024-04-02T06:39:02.653386Z","iopub.status.idle":"2024-04-02T06:39:02.774945Z","shell.execute_reply.started":"2024-04-02T06:39:02.653355Z","shell.execute_reply":"2024-04-02T06:39:02.773903Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Gradient of w: tensor(-15.)\nGradient of b: tensor(-5.)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Full model development flow example (FashionMNIST)","metadata":{}},{"cell_type":"code","source":"# Checking the availability of GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:48:48.686861Z","iopub.execute_input":"2024-04-02T17:48:48.687827Z","iopub.status.idle":"2024-04-02T17:48:48.748991Z","shell.execute_reply.started":"2024-04-02T17:48:48.687796Z","shell.execute_reply":"2024-04-02T17:48:48.747926Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# Define the CNN architecture\nclass FashionCNN(nn.Module):\n    def __init__(self):\n        # Calling nn.Module init method\n        super(FashionCNN, self).__init__() # Similar to super().___init__()\n        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) \n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=1)\n        # The input shape of the linear layer below correspond to the number of pixels\n        # after the input has been flattened, which is output channel of previous channel * height * width.\n        self.fc1 = nn.Linear(16 * 5 * 5, 128)\n        self.fc2 = nn.Linear(128, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.maxpool(out)\n        out = self.conv2(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n        out = out.view(-1, 16*5*5) # Equivalent to flat layers (Reshape tensor). -1 let pytorch infer the second dimension\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.fc2(out)\n        out = self.relu(out)\n        out = self.fc3(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:48:51.421993Z","iopub.execute_input":"2024-04-02T17:48:51.422830Z","iopub.status.idle":"2024-04-02T17:48:51.432221Z","shell.execute_reply.started":"2024-04-02T17:48:51.422799Z","shell.execute_reply":"2024-04-02T17:48:51.431290Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Initialize the model, loss function, and optimizer\nmodel = FashionCNN().to(device)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nsummary(model, input_size=(1, 1, 28, 28))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:48:54.054693Z","iopub.execute_input":"2024-04-02T17:48:54.055302Z","iopub.status.idle":"2024-04-02T17:48:54.877125Z","shell.execute_reply.started":"2024-04-02T17:48:54.055274Z","shell.execute_reply":"2024-04-02T17:48:54.876263Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nFashionCNN                               [1, 10]                   --\n├─Conv2d: 1-1                            [1, 6, 26, 26]            156\n├─ReLU: 1-2                              [1, 6, 26, 26]            --\n├─MaxPool2d: 1-3                         [1, 6, 13, 13]            --\n├─Conv2d: 1-4                            [1, 16, 11, 11]           2,416\n├─ReLU: 1-5                              [1, 16, 11, 11]           --\n├─MaxPool2d: 1-6                         [1, 16, 5, 5]             --\n├─Linear: 1-7                            [1, 128]                  51,328\n├─ReLU: 1-8                              [1, 128]                  --\n├─Linear: 1-9                            [1, 84]                   10,836\n├─ReLU: 1-10                             [1, 84]                   --\n├─Linear: 1-11                           [1, 10]                   850\n==========================================================================================\nTotal params: 65,586\nTrainable params: 65,586\nNon-trainable params: 0\nTotal mult-adds (M): 0.46\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.05\nParams size (MB): 0.26\nEstimated Total Size (MB): 0.32\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"# Inspecting the first fully connected layer of the model\nfc1_weights = model.fc1.weight\nprint(fc1_weights)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:50:19.760128Z","iopub.execute_input":"2024-04-02T17:50:19.760939Z","iopub.status.idle":"2024-04-02T17:50:19.768692Z","shell.execute_reply.started":"2024-04-02T17:50:19.760907Z","shell.execute_reply":"2024-04-02T17:50:19.767747Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Parameter containing:\ntensor([[-0.0494, -0.0297, -0.0040,  ...,  0.0356, -0.0077, -0.0308],\n        [-0.0071, -0.0481,  0.0284,  ...,  0.0481,  0.0322,  0.0346],\n        [ 0.0097,  0.0327,  0.0022,  ..., -0.0499, -0.0491,  0.0098],\n        ...,\n        [ 0.0453,  0.0357, -0.0247,  ...,  0.0432, -0.0361,  0.0360],\n        [ 0.0254, -0.0240,  0.0361,  ...,  0.0056,  0.0024,  0.0409],\n        [ 0.0272,  0.0016, -0.0474,  ...,  0.0468,  0.0381,  0.0329]],\n       device='cuda:0', requires_grad=True)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As we can see, by default, all tensors used for storing model's parameters have their `requires_grad` property set to true. Without `requires_grad` property set to true, we won't able to find its gradient with Autograd during back propagation.","metadata":{}},{"cell_type":"code","source":"# Getting the number of weights of the first fully connected layer\nlen(fc1_weights[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:52:38.736664Z","iopub.execute_input":"2024-04-02T17:52:38.737344Z","iopub.status.idle":"2024-04-02T17:52:38.745523Z","shell.execute_reply.started":"2024-04-02T17:52:38.737316Z","shell.execute_reply":"2024-04-02T17:52:38.744602Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"400"},"metadata":{}}]},{"cell_type":"markdown","source":"Here, the number of weights of the 1st fully connected layer is 400 weights. This is derived from the dimensions of the output of the previous convolutional layer (16, 5, 5) that has been flattenned into 1d vector (16 * 5 * 5 = 400).","metadata":{}},{"cell_type":"code","source":"# Transformations to be applied to each image\ntransform = transforms.Compose([\n    transforms.ToTensor(), \n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load the Fashion-MNIST dataset\nroot = os.path.join(os.getcwd(),\"FMNIST\")\ntrain_dataset = datasets.FashionMNIST(\n    root=root, \n    train=True, \n    download=True, \n    transform=transform\n)\n\ntest_dataset = datasets.FashionMNIST(\n    root=root, \n    train=False, \n    download=True, \n    transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:26:46.348912Z","iopub.execute_input":"2024-04-02T15:26:46.349472Z","iopub.status.idle":"2024-04-02T15:26:51.543417Z","shell.execute_reply.started":"2024-04-02T15:26:46.349434Z","shell.execute_reply":"2024-04-02T15:26:51.542390Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26421880/26421880 [00:01<00:00, 18201401.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29515/29515 [00:00<00:00, 269438.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4422102/4422102 [00:00<00:00, 5096781.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5148/5148 [00:00<00:00, 7499922.54it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/working/FMNIST/FashionMNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Inspecting the type of dataset\ntype(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T07:23:09.949431Z","iopub.execute_input":"2024-04-02T07:23:09.949841Z","iopub.status.idle":"2024-04-02T07:23:09.956824Z","shell.execute_reply.started":"2024-04-02T07:23:09.949811Z","shell.execute_reply":"2024-04-02T07:23:09.955778Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"torchvision.datasets.mnist.FashionMNIST"},"metadata":{}}]},{"cell_type":"code","source":"# Create data loaders (Iterable) to load dataset in batches (List of Tensors).\ntrain_loader = torch.utils.data.DataLoader(\n    dataset=train_dataset, \n    batch_size=4, \n    shuffle=True\n)\ntest_loader = torch.utils.data.DataLoader(\n    dataset=test_dataset, \n    batch_size=4, \n    shuffle=False\n)\n\n# Class labels\nclasses = (\n    'T-shirt/top',\n    'Trouser',\n    'Pullover',\n    'Dress',\n    'Coat',\n    'Sandal',\n    'Shirt',\n    'Sneaker',\n    'Bag',\n    'Ankle Boot'\n)\n\n# Display split sizes\nprint(\"Training size: {}\".format(len(train_dataset)))\nprint(\"Validation size: {}\".format(len(test_dataset)))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:27:27.673856Z","iopub.execute_input":"2024-04-02T15:27:27.674546Z","iopub.status.idle":"2024-04-02T15:27:27.681699Z","shell.execute_reply.started":"2024-04-02T15:27:27.674511Z","shell.execute_reply":"2024-04-02T15:27:27.680710Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Training size: 60000\nValidation size: 10000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Inspecting the type of data loader\ntype(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T07:16:12.555395Z","iopub.execute_input":"2024-04-02T07:16:12.556153Z","iopub.status.idle":"2024-04-02T07:16:12.562307Z","shell.execute_reply.started":"2024-04-02T07:16:12.556119Z","shell.execute_reply":"2024-04-02T07:16:12.561331Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"torch.utils.data.dataloader.DataLoader"},"metadata":{}}]},{"cell_type":"code","source":"# Getting & displaying the first batch of data\n# 1st element of the list -> A single batch of images (4 Images).\n# 2nd element of the list -> A list containing corresponding labels for each image.\nx = iter(train_loader)\nsample = next(x)\nsample","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:28:32.064246Z","iopub.execute_input":"2024-04-02T15:28:32.064636Z","iopub.status.idle":"2024-04-02T15:28:32.186400Z","shell.execute_reply.started":"2024-04-02T15:28:32.064611Z","shell.execute_reply":"2024-04-02T15:28:32.185400Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -0.9843, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -0.8902,  ..., -0.7647, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -0.5216,  ..., -0.4980, -1.0000, -1.0000],\n           ...,\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9843, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n \n \n         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           ...,\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n \n \n         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           ...,\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n \n \n         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           ...,\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]]),\n tensor([0, 0, 7, 2])]"},"metadata":{}}]},{"cell_type":"code","source":"# Getting an individual image from the batch\ntemp = sample[0][0]\nprint(temp.shape)\ntemp","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:38:07.960692Z","iopub.execute_input":"2024-04-02T15:38:07.961858Z","iopub.status.idle":"2024-04-02T15:38:07.979206Z","shell.execute_reply.started":"2024-04-02T15:38:07.961813Z","shell.execute_reply":"2024-04-02T15:38:07.978228Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"torch.Size([1, 28, 28])\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"tensor([[[-1.0000, -1.0000, -1.0000, -0.4980, -0.5216, -0.5529, -0.4824,\n          -0.5529, -0.4980, -0.6863, -0.6706, -0.7255, -0.7647, -0.7647,\n          -0.8196, -0.7255, -0.6863, -0.6078, -0.6471, -0.6863, -0.7020,\n          -0.5765, -0.5373, -0.5373, -0.5216, -0.9843, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -0.8902, -0.4431, -0.4980, -0.5216, -0.3098,\n          -0.5216, -0.4431, -0.4275, -0.3882, -0.4588, -0.5373, -0.5765,\n          -0.4431, -0.3098, -0.6078, -0.5922, -0.3647, -0.4039, -0.5765,\n          -0.4980, -0.5216, -0.6314, -0.4431, -0.7647, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -0.5216, -0.5373, -0.5529, -0.4275, -0.0902,\n          -0.4275, -0.3882, -0.3882, -0.4275, -0.6078, -0.6314, -0.6314,\n          -0.4588, -0.3490, -0.6706, -0.5922, -0.5765, -0.4275, -0.6314,\n          -0.3882, -0.2549, -0.7020, -0.4824, -0.4980, -1.0000, -1.0000],\n         [-1.0000, -0.9843, -0.4039, -0.5529, -0.5765, -0.1843,  0.2706,\n          -0.3098, -0.3333, -0.3647, -0.5216, -0.6706, -0.6863, -0.7255,\n          -0.4824, -0.3490, -0.7255, -0.6471, -0.6314, -0.4824, -0.6471,\n          -0.2784, -0.1843, -0.7020, -0.4824, -0.2784, -0.9686, -1.0000],\n         [-1.0000, -0.9451, -0.3333, -0.6471, -0.5216, -0.1216,  0.5686,\n          -0.3333, -0.2549, -0.4039, -0.4588, -0.5529, -0.7020, -0.7255,\n          -0.3647, -0.3333, -0.7647, -0.6078, -0.5373, -0.5216, -0.6471,\n          -0.1451,  0.0039, -0.7020, -0.5373, -0.1059, -0.7647, -1.0000],\n         [-1.0000, -0.8902, -0.2000, -0.6706, -0.3882, -0.2941,  0.6235,\n          -0.4588, -0.0118, -0.4431, -0.2000, -0.3333, -0.7647, -0.6471,\n          -0.1216, -0.4431, -0.7412, -0.4431, -0.4980, -0.5216, -0.6863,\n          -0.1843,  0.3569, -0.6863, -0.7020, -0.1216, -0.4588, -1.0000],\n         [-1.0000, -0.8902, -0.0667, -0.6863, -0.2000, -0.4588,  0.6627,\n          -0.6078,  0.2314, -0.5765, -0.0353, -0.2549, -0.8745, -0.6706,\n           0.0275, -0.5216, -0.8353, -0.3647, -0.4275, -0.4824, -0.7804,\n          -0.2000,  0.6235, -0.6471, -0.7961, -0.1216, -0.2392, -0.9137],\n         [-1.0000, -0.6706,  0.0588, -0.7804, -0.1843, -0.4824,  0.6000,\n          -0.7961,  0.8118, -0.5373, -0.2157, -0.2549, -0.7961, -0.7255,\n           0.1922, -0.8510, -0.8196, -0.3647, -0.9137, -0.6706, -0.6863,\n          -0.3490,  0.4196, -0.4980, -0.8902, -0.2392, -0.1843, -0.8196],\n         [-1.0000, -0.3333,  0.0824, -0.8353,  0.0275, -0.5529,  0.7176,\n          -1.0000,  0.9059, -0.5922, -0.9294, -0.7255, -0.9294, -0.8510,\n           0.6000, -0.4275, -0.9137, -0.3647,  0.2863, -0.5216, -0.9843,\n          -0.1843,  0.6392, -0.1059, -0.7804, -0.2784,  0.2078, -0.6078],\n         [-1.0000, -0.5373, -0.3647, -0.8902,  0.0039, -0.3098,  1.0000,\n          -0.2549,  0.6000, -0.2000,  0.0431, -0.0118, -0.2000, -0.5529,\n           0.4353,  0.7333,  0.6235,  0.3804,  0.8824,  0.9059, -0.0510,\n          -0.7412,  0.0431, -0.3333, -0.7647, -0.7020,  0.0824, -0.6314],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9686,\n          -0.7412,  0.5137,  0.4353,  0.5137,  0.8824,  0.2863, -0.4980,\n          -0.5216, -0.7647, -0.5529, -0.4039, -0.5529,  0.2706, -0.4980,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000,  0.2471, -0.1451, -0.5373, -0.6078, -0.6706, -0.6471,\n          -0.6314, -0.5765, -0.6471, -0.6863, -0.6314, -0.6078, -0.8902,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.9843,  0.0980, -0.3647, -0.3647, -0.4824, -0.5373, -0.5216,\n          -0.5529, -0.5922, -0.5922, -0.6078, -0.6471, -0.4980, -0.7020,\n          -1.0000, -1.0000, -1.0000, -0.9843, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.8196, -0.1216, -0.5922, -0.4980, -0.5373, -0.5373, -0.5529,\n          -0.5922, -0.5922, -0.6078, -0.5922, -0.6314, -0.5529, -0.7255,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.5373, -0.3098, -0.6314, -0.5529, -0.5373, -0.5765, -0.6078,\n          -0.5922, -0.6078, -0.6078, -0.6314, -0.5922, -0.5922, -0.5765,\n          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -0.4275, -0.5373, -0.5529, -0.5529, -0.5373, -0.5765, -0.5922,\n          -0.6078, -0.6078, -0.6078, -0.6314, -0.5922, -0.6471, -0.4980,\n          -0.8510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8745,\n          -0.1216, -0.4980, -0.5529, -0.5765, -0.5373, -0.5216, -0.4980,\n          -0.5529, -0.5529, -0.5922, -0.6078, -0.6314, -0.6706, -0.4824,\n          -0.6706, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8745,\n           0.0039, -0.4275, -0.5765, -0.5216, -0.4980, -0.4980, -0.4824,\n          -0.4824, -0.4980, -0.5373, -0.5373, -0.5529, -0.5529, -0.4824,\n          -0.5529, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -0.9843, -1.0000, -0.4275,\n          -0.0353, -0.4431, -0.4431, -0.4824, -0.4588, -0.4431, -0.4431,\n          -0.4431, -0.4588, -0.4824, -0.4824, -0.5373, -0.5373, -0.5529,\n          -0.4588, -0.9843, -1.0000, -0.9843, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -0.9686, -1.0000, -0.2549,\n           0.0275, -0.3882, -0.4039, -0.4275, -0.3882, -0.3647, -0.3882,\n          -0.4275, -0.4039, -0.4824, -0.4588, -0.4980, -0.4824, -0.5765,\n          -0.2784, -0.8902, -1.0000, -0.9843, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9451,\n          -0.4039, -0.2157, -0.3490, -0.5216, -0.5216, -0.4588, -0.4588,\n          -0.3882, -0.4824, -0.4980, -0.4980, -0.5529, -0.5922, -0.4275,\n          -0.4824, -1.0000, -1.0000, -0.9843, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -0.7412, -0.4039, -0.2392, -0.3647, -0.6471, -0.7020,\n          -0.7255, -0.6706, -0.5922, -0.5373, -0.1843, -0.2392, -0.6078,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -0.8745, -0.4039,  0.3412,  0.1922,\n           0.1922,  0.0980,  0.2078, -0.1608, -0.7647, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -0.9843, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3882,  0.3412,\n           0.0039,  0.1922, -0.1451, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -0.9843, -1.0000, -1.0000,  0.1922,\n           0.0275,  0.0588, -1.0000, -1.0000, -0.9294, -0.9843, -0.9843,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -0.9843, -0.9843, -1.0000,  0.0588,\n           0.2706, -0.1059, -1.0000, -0.9843, -0.9843, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -0.9843, -1.0000,  0.3020,\n           0.7569,  0.2706, -1.0000, -0.9843, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843, -1.0000],\n         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n          -1.0000, -1.0000, -0.9843, -1.0000, -0.9843, -1.0000, -0.0667,\n           0.3961,  0.0980, -1.0000, -1.0000, -0.9843, -1.0000, -1.0000,\n          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"},"metadata":{}}]},{"cell_type":"code","source":"# Checking the requires_grad attribute of input tensor\ntemp.requires_grad","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:41:47.208715Z","iopub.execute_input":"2024-04-02T15:41:47.209098Z","iopub.status.idle":"2024-04-02T15:41:47.215640Z","shell.execute_reply.started":"2024-04-02T15:41:47.209065Z","shell.execute_reply":"2024-04-02T15:41:47.214710Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"markdown","source":"**REMEMBER! WE DON'T COMPUTE GRADIENTS FOR INPUT DATA BUT FOR MODEL PARAMETERS (Weights & Biases)**","metadata":{}},{"cell_type":"code","source":"# Sanity check (Visualizing the first batch of images & labels)\ndef matplotlib_imshow(img, one_channel=False):\n  if one_channel:\n    img = img.mean(dim=0)\n  img = img / 2 + 0.5\n  npimg = img.numpy()\n  if one_channel:\n    plt.imshow(npimg, cmap=\"Greys\")\n  else:\n    plt.imshow(np.transpose(npimg, (1,2,0)))\n\n# The dataloader implement the iter protocol (iter magic method),\n# thus to access data within it (batches of image & label)\n# we must create an iterator object from it.\ndataiter = iter(train_loader)\n# Getting the first batch of images & labels (32 pairs)\nimages, labels = next(dataiter)\n\n# Create a grid from the images and show them\nimg_grid = torchvision.utils.make_grid(images)\nmatplotlib_imshow(img_grid, one_channel=True)\nprint('Image shape: ', images.shape)\nprint(' '.join(classes[labels[j]] for j in range(len(labels))))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:54:03.929965Z","iopub.execute_input":"2024-04-02T09:54:03.930780Z","iopub.status.idle":"2024-04-02T09:54:04.196970Z","shell.execute_reply.started":"2024-04-02T09:54:03.930746Z","shell.execute_reply":"2024-04-02T09:54:04.196093Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Image shape:  torch.Size([4, 1, 28, 28])\nAnkle Boot Coat Sneaker Sneaker\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Training function\ndef train_one_epoch(epoch_index, tb_writer):\n  running_loss = 0.\n  last_loss = 0.\n\n  # Looping each batch of data\n  for i, (inputs, labels) in enumerate(train_loader):\n    # Every data instance is a batch of image & label pairs.\n    inputs, labels = inputs.to(device), labels.to(device)\n    # Setting the gradient to zero for every batch (Mini-batch gradient descent)\n    optimizer.zero_grad()\n    # Compute the predictions for this batch (The forward method is called implicitly)\n    outputs = model(inputs)\n    # Compute the loss \n    loss = loss_fn(outputs, labels)\n    # Compute the gradients using autograd\n    loss.backward()\n    # Adjusting the learning weights (Backprop)\n    optimizer.step()\n    # Logging the loss for each 1k batches.\n    # For the current config (4 batches), there will be 15k batches in 1 epoch.\n    running_loss += loss.item()\n    if i % 1000 == 999:\n      last_loss = running_loss / 1000\n      print(f'Batch {i+1} loss: {last_loss}')\n      # Visualizing with tensorboard\n      tb_x = epoch_index * len(train_loader) + i + 1\n      tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n      running_loss = 0.\n\n  return last_loss","metadata":{"execution":{"iopub.status.busy":"2024-03-25T18:57:12.531483Z","iopub.execute_input":"2024-03-25T18:57:12.531854Z","iopub.status.idle":"2024-03-25T18:57:12.539487Z","shell.execute_reply.started":"2024-03-25T18:57:12.531827Z","shell.execute_reply":"2024-03-25T18:57:12.538502Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Training loop\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nwriter = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\nepoch_number = 0\nEPOCHS = 5\nbest_vloss = 1_000_000. # vloss -> validation loss\nfor epoch in range(EPOCHS):\n  print('\\nEPOCH {}:'.format(epoch_number + 1))\n  # Set the model to training mode\n  model.train(True)\n  # Calling the training function\n  avg_loss = train_one_epoch(epoch_number, writer)\n  running_vloss = 0.0\n  # Set the model to evaluation mode\n  model.eval()\n  # Temporarily disable gradient computation during inference for validation data.\n  with torch.no_grad():\n    for i, (vinputs, vlabels) in enumerate(test_loader):\n      vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n      voutputs = model(vinputs)\n      vloss = loss_fn(voutputs, vlabels)\n      running_vloss += vloss\n\n  avg_vloss = running_vloss / (i + 1)\n  print('Training loss: {}, validation loss: {}'.format(avg_loss, avg_vloss))\n\n  # Log the average running loss per batch for training & validation\n  writer.add_scalars(\n      'Training vs. Validation Loss',\n      {'Training': avg_loss, 'Validation': avg_vloss},\n      epoch_number + 1\n  )\n  writer.flush()\n\n  # Track best performance, and save the model's sate\n  if avg_vloss < best_vloss:\n    best_vloss = avg_vloss\n    model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n    torch.save(model.state_dict(), model_path)\n\n  epoch_number += 1","metadata":{"execution":{"iopub.status.busy":"2024-03-25T18:57:15.955957Z","iopub.execute_input":"2024-03-25T18:57:15.956701Z","iopub.status.idle":"2024-03-25T19:01:08.008389Z","shell.execute_reply.started":"2024-03-25T18:57:15.956665Z","shell.execute_reply":"2024-03-25T19:01:08.007462Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\nEPOCH 1:\nBatch 1000 loss: 1.9121681880652905\nBatch 2000 loss: 0.8608711149208248\nBatch 3000 loss: 0.6797803851682693\nBatch 4000 loss: 0.6117923960955813\nBatch 5000 loss: 0.5623956329380162\nBatch 6000 loss: 0.5267888390785083\nBatch 7000 loss: 0.5129248777227476\nBatch 8000 loss: 0.4892858238525223\nBatch 9000 loss: 0.46392954911629203\nBatch 10000 loss: 0.4460567360999412\nBatch 11000 loss: 0.40707099902589106\nBatch 12000 loss: 0.4167586170655559\nBatch 13000 loss: 0.38594459228112826\nBatch 14000 loss: 0.40500220755289773\nBatch 15000 loss: 0.391686304132214\nTraining loss: 0.391686304132214, validation loss: 0.4003625214099884\n\nEPOCH 2:\nBatch 1000 loss: 0.3785476180012047\nBatch 2000 loss: 0.3685678926896362\nBatch 3000 loss: 0.35906948553479745\nBatch 4000 loss: 0.3564164625175326\nBatch 5000 loss: 0.33903039502090543\nBatch 6000 loss: 0.3526441483788658\nBatch 7000 loss: 0.3632479494495492\nBatch 8000 loss: 0.3118566998069218\nBatch 9000 loss: 0.3406563904377981\nBatch 10000 loss: 0.34847392105381003\nBatch 11000 loss: 0.3508664501240819\nBatch 12000 loss: 0.31980952185994826\nBatch 13000 loss: 0.34559136797624523\nBatch 14000 loss: 0.33425253419711953\nBatch 15000 loss: 0.32226610166557657\nTraining loss: 0.32226610166557657, validation loss: 0.34786278009414673\n\nEPOCH 3:\nBatch 1000 loss: 0.3165551162105548\nBatch 2000 loss: 0.298145625373254\nBatch 3000 loss: 0.28919095998712874\nBatch 4000 loss: 0.3129149286414031\nBatch 5000 loss: 0.30226888183140543\nBatch 6000 loss: 0.2939505933850269\nBatch 7000 loss: 0.31842287083032716\nBatch 8000 loss: 0.30156959955469936\nBatch 9000 loss: 0.2924455620779145\nBatch 10000 loss: 0.31547435028250403\nBatch 11000 loss: 0.2834788253849347\nBatch 12000 loss: 0.30486597994761544\nBatch 13000 loss: 0.3102456152500563\nBatch 14000 loss: 0.3057217241906501\nBatch 15000 loss: 0.2979036838693137\nTraining loss: 0.2979036838693137, validation loss: 0.31272438168525696\n\nEPOCH 4:\nBatch 1000 loss: 0.2771169750119991\nBatch 2000 loss: 0.2779287270377681\nBatch 3000 loss: 0.2733626817001168\nBatch 4000 loss: 0.2744519800521812\nBatch 5000 loss: 0.28460864309406314\nBatch 6000 loss: 0.265529544564346\nBatch 7000 loss: 0.2887355772587389\nBatch 8000 loss: 0.2675796078513904\nBatch 9000 loss: 0.28170124320585455\nBatch 10000 loss: 0.28123225795674445\nBatch 11000 loss: 0.26419804175510037\nBatch 12000 loss: 0.27428389300289563\nBatch 13000 loss: 0.26379283412410043\nBatch 14000 loss: 0.2892058217310041\nBatch 15000 loss: 0.28454447202407757\nTraining loss: 0.28454447202407757, validation loss: 0.2912951111793518\n\nEPOCH 5:\nBatch 1000 loss: 0.2695863891842673\nBatch 2000 loss: 0.25257739862705786\nBatch 3000 loss: 0.2608963511697648\nBatch 4000 loss: 0.2556995280092342\nBatch 5000 loss: 0.24445074512780593\nBatch 6000 loss: 0.24766009270775066\nBatch 7000 loss: 0.24447414594266412\nBatch 8000 loss: 0.2561405856132949\nBatch 9000 loss: 0.25470053003366955\nBatch 10000 loss: 0.2498739246298437\nBatch 11000 loss: 0.2479463080971882\nBatch 12000 loss: 0.27059737942121503\nBatch 13000 loss: 0.25583040575017\nBatch 14000 loss: 0.26520508533150494\nBatch 15000 loss: 0.27047982138246923\nTraining loss: 0.27047982138246923, validation loss: 0.2930011451244354\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pre-trained weights\nmodel.load_state_dict(torch.load('/kaggle/input/variant_1/pytorch/test-1/1/model_20240325_185715_2'))","metadata":{"execution":{"iopub.status.busy":"2024-03-27T04:10:32.328641Z","iopub.execute_input":"2024-03-27T04:10:32.329330Z","iopub.status.idle":"2024-03-27T04:10:32.384122Z","shell.execute_reply.started":"2024-03-27T04:10:32.329298Z","shell.execute_reply":"2024-03-27T04:10:32.383208Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"test_loader","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating multiclassification metrics & confusion matrix\nmodel.eval()\nwith torch.no_grad():\n    for vinputs, vlabels in test_loader:\n        vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n        voutputs = model(vinputs)\n        # Sending back the outputs & label to CPU\n        voutputs = voutputs.detach().cpu().numpy()\n        vlabels = vlabels.detach().cpu().numpy()\n    \nprecision = precision_score(vlabels, voutputs.argmax(axis=1), average='macro')\nrecall = recall_score(vlabels, voutputs.argmax(axis=1), average='macro')\nf1 = f1_score(vlabels, voutputs.argmax(axis=1), average='macro')\n\nprint('Precission: ', precision)\nprint('Recall: ', recall)\nprint('F1_Macro: ', f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T04:13:06.171763Z","iopub.execute_input":"2024-03-27T04:13:06.172809Z","iopub.status.idle":"2024-03-27T04:13:10.079643Z","shell.execute_reply.started":"2024-03-27T04:13:06.172767Z","shell.execute_reply":"2024-03-27T04:13:10.078595Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Precission:  1.0\nRecall:  1.0\nF1_Macro:  1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"voutputs.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T04:13:39.455503Z","iopub.execute_input":"2024-03-27T04:13:39.455872Z","iopub.status.idle":"2024-03-27T04:13:39.462509Z","shell.execute_reply.started":"2024-03-27T04:13:39.455844Z","shell.execute_reply":"2024-03-27T04:13:39.461450Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([1, 8, 1, 5])"},"metadata":{}}]},{"cell_type":"code","source":"vlabels","metadata":{"execution":{"iopub.status.busy":"2024-03-27T04:14:01.417316Z","iopub.execute_input":"2024-03-27T04:14:01.417675Z","iopub.status.idle":"2024-03-27T04:14:01.423583Z","shell.execute_reply.started":"2024-03-27T04:14:01.417649Z","shell.execute_reply":"2024-03-27T04:14:01.422707Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([1, 8, 1, 5])"},"metadata":{}}]},{"cell_type":"markdown","source":"Calculate accuracy too, or matrix for better.","metadata":{}},{"cell_type":"code","source":"# Final save for model & weights\ntorch.save(model, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-25T19:08:18.251534Z","iopub.execute_input":"2024-03-25T19:08:18.252424Z","iopub.status.idle":"2024-03-25T19:08:18.259355Z","shell.execute_reply.started":"2024-03-25T19:08:18.252392Z","shell.execute_reply":"2024-03-25T19:08:18.258457Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Multimodal Model Experiment","metadata":{}}]}