{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T04:05:03.676969Z",
     "iopub.status.busy": "2024-03-27T04:05:03.676733Z",
     "iopub.status.idle": "2024-03-27T04:05:18.132469Z",
     "shell.execute_reply": "2024-03-27T04:05:18.131317Z",
     "shell.execute_reply.started": "2024-03-27T04:05:03.676946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing libraries\n",
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Pytorch Model and training necessities\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary # For model architecture summary\n",
    "\n",
    "# Model performance evaluation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Pytorch tensorboard support\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the availability of GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Calling nn.Module init method\n",
    "        super(FashionCNN, self).__init__() # Similar to super().___init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=1)\n",
    "        # The input shape of the linear layer below correspond to the number of pixels\n",
    "        # after the input has been flattened, which is output channel of previous channel * height * width.\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(-1, 16*5*5) # Equivalent to flat layers (Reshape tensor). -1 let pytorch infer the second dimension\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FashionCNN                               [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 6, 26, 26]            156\n",
       "├─ReLU: 1-2                              [1, 6, 26, 26]            --\n",
       "├─MaxPool2d: 1-3                         [1, 6, 13, 13]            --\n",
       "├─Conv2d: 1-4                            [1, 16, 11, 11]           2,416\n",
       "├─ReLU: 1-5                              [1, 16, 11, 11]           --\n",
       "├─MaxPool2d: 1-6                         [1, 16, 5, 5]             --\n",
       "├─Linear: 1-7                            [1, 128]                  51,328\n",
       "├─ReLU: 1-8                              [1, 128]                  --\n",
       "├─Linear: 1-9                            [1, 84]                   10,836\n",
       "├─ReLU: 1-10                             [1, 84]                   --\n",
       "├─Linear: 1-11                           [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 65,586\n",
       "Trainable params: 65,586\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.46\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.26\n",
       "Estimated Total Size (MB): 0.32\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = FashionCNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "summary(model, input_size=(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformations to be applied to each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the Fashion-MNIST dataset (download the dataset if it's not already available)\n",
    "root = os.path.join(os.getcwd(),\"dataset\")\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=root, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=root, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 60000\n",
      "Validation size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders to load dataset in batch.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=4, \n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=4, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Class labels\n",
    "classes = (\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle Boot'\n",
    ")\n",
    "\n",
    "# Display split sizes\n",
    "print(\"Training size: {}\".format(len(train_dataset)))\n",
    "print(\"Validation size: {}\".format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  torch.Size([4, 1, 28, 28])\n",
      "Pullover Ankle Boot T-shirt/top Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check (Visualizing the first batch of images & labels)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "  if one_channel:\n",
    "    img = img.mean(dim=0)\n",
    "  img = img / 2 + 0.5\n",
    "  npimg = img.numpy()\n",
    "  if one_channel:\n",
    "    plt.imshow(npimg, cmap=\"Greys\")\n",
    "  else:\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# The dataloader implement the iter protocol (iter magic method),\n",
    "# thus to access data within it (batches of image & label)\n",
    "# we must create an iterator object from it.\n",
    "dataiter = iter(train_loader)\n",
    "# Getting the first batch of images & labels (32 pairs)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('Image shape: ', images.shape)\n",
    "print(' '.join(classes[labels[j]] for j in range(len(labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing sample images to tensorboard\n",
    "# Instantiating a SummaryWriter object. Signature: SummaryWriter('dir/tag'), the default dir is ./runs/.\n",
    "writer = SummaryWriter('runs/fashion_mnist')\n",
    "# Adding the image grid\n",
    "writer.add_image('Four FashionMNIST images 2', img_grid)\n",
    "# Write all pending events to disk\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "  running_loss = 0.\n",
    "  last_loss = 0.\n",
    "\n",
    "  # Looping each batch of data\n",
    "  for i, (inputs, labels) in enumerate(train_loader):\n",
    "    # Every data instance is a batch of image & label pairs.\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # Setting the gradient to zero for every batch (Mini-batch gradient descent)\n",
    "    optimizer.zero_grad()\n",
    "    # Compute the predictions for this batch (The forward method is called implicitly)\n",
    "    outputs = model(inputs)\n",
    "    # Compute the loss \n",
    "    loss = loss_fn(outputs, labels)\n",
    "    # Compute the gradients using autograd\n",
    "    loss.backward()\n",
    "    # Adjusting the learning weights (Backprop)\n",
    "    optimizer.step()\n",
    "    # Logging the loss for each 1k batches.\n",
    "    # For the current config (4 batches), there will be 15k batches in 1 epoch.\n",
    "    running_loss += loss.item()\n",
    "    if i % 1000 == 999:\n",
    "      last_loss = running_loss / 1000\n",
    "      print(f'Batch {i+1} loss: {last_loss}')\n",
    "      # Visualizing with tensorboard\n",
    "      tb_x = epoch_index * len(train_loader) + i + 1\n",
    "      tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "      running_loss = 0.\n",
    "\n",
    "  return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\n",
      "Batch 1000 loss: 1.6935092932879925\n",
      "Batch 2000 loss: 0.7964923129491508\n",
      "Batch 3000 loss: 0.6843814545702189\n",
      "Batch 4000 loss: 0.5934257045909762\n",
      "Batch 5000 loss: 0.5754465280887671\n",
      "Batch 6000 loss: 0.5208729945053346\n",
      "Batch 7000 loss: 0.4812990891374648\n",
      "Batch 8000 loss: 0.47404948402300945\n",
      "Batch 9000 loss: 0.4753556819287478\n",
      "Batch 10000 loss: 0.45554060108569683\n",
      "Batch 11000 loss: 0.4420226871923078\n",
      "Batch 12000 loss: 0.4057664921041869\n",
      "Batch 13000 loss: 0.41184616823491527\n",
      "Batch 14000 loss: 0.3945435380007184\n",
      "Batch 15000 loss: 0.3815532859823434\n",
      "Training loss: 0.3815532859823434, validation loss: 0.406253457069397\n",
      "\n",
      "EPOCH 2:\n",
      "Batch 1000 loss: 0.37927764279543774\n",
      "Batch 2000 loss: 0.3902988552075403\n",
      "Batch 3000 loss: 0.37117619880595887\n",
      "Batch 4000 loss: 0.3661907038381032\n",
      "Batch 5000 loss: 0.3902758456920128\n",
      "Batch 6000 loss: 0.3439492403399199\n",
      "Batch 7000 loss: 0.34273655101879924\n",
      "Batch 8000 loss: 0.3425112566638272\n",
      "Batch 9000 loss: 0.33756579473233433\n",
      "Batch 10000 loss: 0.347045003929903\n",
      "Batch 11000 loss: 0.3247162744002926\n",
      "Batch 12000 loss: 0.3257843560588226\n",
      "Batch 13000 loss: 0.30676985737358337\n",
      "Batch 14000 loss: 0.33015896723332117\n",
      "Batch 15000 loss: 0.3133238432637445\n",
      "Training loss: 0.3133238432637445, validation loss: 0.3396858274936676\n",
      "\n",
      "EPOCH 3:\n",
      "Batch 1000 loss: 0.32632314604893325\n",
      "Batch 2000 loss: 0.30265959722115077\n",
      "Batch 3000 loss: 0.2963932604320289\n",
      "Batch 4000 loss: 0.2987506753323578\n",
      "Batch 5000 loss: 0.2780888726164703\n",
      "Batch 6000 loss: 0.30145271233564197\n",
      "Batch 7000 loss: 0.30164022091747755\n",
      "Batch 8000 loss: 0.28750832354948214\n",
      "Batch 9000 loss: 0.30964224543778257\n",
      "Batch 10000 loss: 0.3142165184914629\n",
      "Batch 11000 loss: 0.306885319695255\n",
      "Batch 12000 loss: 0.304319126276474\n",
      "Batch 13000 loss: 0.29427590631767997\n",
      "Batch 14000 loss: 0.299486257253011\n",
      "Batch 15000 loss: 0.29866464200284465\n",
      "Training loss: 0.29866464200284465, validation loss: 0.3586227595806122\n",
      "\n",
      "EPOCH 4:\n",
      "Batch 1000 loss: 0.2800309840761975\n",
      "Batch 2000 loss: 0.2603770180312331\n",
      "Batch 3000 loss: 0.27835375549337094\n",
      "Batch 4000 loss: 0.2588314916159434\n",
      "Batch 5000 loss: 0.27709759733674943\n",
      "Batch 6000 loss: 0.2632368117861633\n",
      "Batch 7000 loss: 0.27654546590970497\n",
      "Batch 8000 loss: 0.2737033687894508\n",
      "Batch 9000 loss: 0.2961004273898743\n",
      "Batch 10000 loss: 0.26143508337192906\n",
      "Batch 11000 loss: 0.27840413149047527\n",
      "Batch 12000 loss: 0.27502120531388935\n",
      "Batch 13000 loss: 0.2789861959550326\n",
      "Batch 14000 loss: 0.27993081910295586\n",
      "Batch 15000 loss: 0.2629181518155292\n",
      "Training loss: 0.2629181518155292, validation loss: 0.33538752794265747\n",
      "\n",
      "EPOCH 5:\n",
      "Batch 1000 loss: 0.25387489083861875\n",
      "Batch 2000 loss: 0.2564791360569898\n",
      "Batch 3000 loss: 0.2677941740137867\n",
      "Batch 4000 loss: 0.2575937410028928\n",
      "Batch 5000 loss: 0.24894383140743584\n",
      "Batch 6000 loss: 0.2554951162150646\n",
      "Batch 7000 loss: 0.24309855613123546\n",
      "Batch 8000 loss: 0.25932859155871757\n",
      "Batch 9000 loss: 0.26076256102751133\n",
      "Batch 10000 loss: 0.2557696283217042\n",
      "Batch 11000 loss: 0.2619619087236897\n",
      "Batch 12000 loss: 0.26039005065484155\n",
      "Batch 13000 loss: 0.24581223375666103\n",
      "Batch 14000 loss: 0.2445343622384189\n",
      "Batch 15000 loss: 0.26948854638166586\n",
      "Training loss: 0.26948854638166586, validation loss: 0.3044252395629883\n",
      "\n",
      "EPOCH 6:\n",
      "Batch 1000 loss: 0.22009770259938113\n",
      "Batch 2000 loss: 0.23728170347746708\n",
      "Batch 3000 loss: 0.2264644043610915\n",
      "Batch 4000 loss: 0.25212872377904566\n",
      "Batch 5000 loss: 0.23397748042980493\n",
      "Batch 6000 loss: 0.2223862940633317\n",
      "Batch 7000 loss: 0.2378978746792277\n",
      "Batch 8000 loss: 0.2392570087876593\n",
      "Batch 9000 loss: 0.24797946748161667\n",
      "Batch 10000 loss: 0.2635224972791066\n",
      "Batch 11000 loss: 0.24719522839344063\n",
      "Batch 12000 loss: 0.24098184599638847\n",
      "Batch 13000 loss: 0.2233276053849072\n",
      "Batch 14000 loss: 0.23134964222308507\n",
      "Batch 15000 loss: 0.26533564494792333\n",
      "Training loss: 0.26533564494792333, validation loss: 0.3008303642272949\n",
      "\n",
      "EPOCH 7:\n",
      "Batch 1000 loss: 0.21434594513640468\n",
      "Batch 2000 loss: 0.2305471053098222\n",
      "Batch 3000 loss: 0.23655971955866517\n",
      "Batch 4000 loss: 0.24226847500154167\n",
      "Batch 5000 loss: 0.21921581962251957\n",
      "Batch 6000 loss: 0.22579271918797578\n",
      "Batch 7000 loss: 0.2175136320762765\n",
      "Batch 8000 loss: 0.21265903349079998\n",
      "Batch 9000 loss: 0.23352562074975594\n",
      "Batch 10000 loss: 0.24868779365791124\n",
      "Batch 11000 loss: 0.2167322080853728\n",
      "Batch 12000 loss: 0.2083852024216394\n",
      "Batch 13000 loss: 0.2448683898759782\n",
      "Batch 14000 loss: 0.21786799059397072\n",
      "Batch 15000 loss: 0.22331422876567059\n",
      "Training loss: 0.22331422876567059, validation loss: 0.27461618185043335\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "EPOCHS = 7\n",
    "best_vloss = 1_000_000. # vloss -> validation loss. Initial validation loss threshold.\n",
    "for epoch in range(EPOCHS):\n",
    "  print('\\nEPOCH {}:'.format(epoch_number + 1))\n",
    "  # Set the model to training mode\n",
    "  model.train(True)\n",
    "  # Calling the training function\n",
    "  avg_loss = train_one_epoch(epoch_number, writer)\n",
    "  running_vloss = 0.0\n",
    "  # Set the model to evaluation mode\n",
    "  model.eval()\n",
    "  # Temporarily disable gradient computation during inference for validation data.\n",
    "  with torch.no_grad():\n",
    "    for i, (vinputs, vlabels) in enumerate(test_loader):\n",
    "      vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "      voutputs = model(vinputs)\n",
    "      vloss = loss_fn(voutputs, vlabels)\n",
    "      running_vloss += vloss\n",
    "\n",
    "  avg_vloss = running_vloss / (i + 1) # i + 1 because index starts from 0.\n",
    "  print('Training loss: {}, validation loss: {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "  # Log the average running loss for training & validation dataset to TensorBoard (at each batch)\n",
    "  writer.add_scalars(\n",
    "      main_tag='Training vs. Validation Loss',\n",
    "      tag_scalar_dict={'Training': avg_loss, 'Validation': avg_vloss},\n",
    "      global_step=epoch_number + 1\n",
    "  )\n",
    "  writer.flush()\n",
    "\n",
    "  # Saved the model state that has the smallest validation loss (savepoint).\n",
    "  if avg_vloss < best_vloss:\n",
    "    best_vloss = avg_vloss\n",
    "    model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "  epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T04:10:32.329330Z",
     "iopub.status.busy": "2024-03-27T04:10:32.328641Z",
     "iopub.status.idle": "2024-03-27T04:10:32.384122Z",
     "shell.execute_reply": "2024-03-27T04:10:32.383208Z",
     "shell.execute_reply.started": "2024-03-27T04:10:32.329298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained weights\n",
    "model.load_state_dict(torch.load('/kaggle/input/variant_1/pytorch/test-1/1/model_20240325_185715_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precission:  1.0\n",
      "Recall:  1.0\n",
      "F1_Macro:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating multiclassification metrics & confusion matrix\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for vinputs, vlabels in test_loader:\n",
    "        vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "        voutputs = model(vinputs)\n",
    "        # Sending back the outputs & label to CPU\n",
    "        voutputs = voutputs.detach().cpu().numpy()\n",
    "        vlabels = vlabels.detach().cpu().numpy()\n",
    "    \n",
    "precision = precision_score(vlabels, voutputs.argmax(axis=1), average='macro')\n",
    "recall = recall_score(vlabels, voutputs.argmax(axis=1), average='macro')\n",
    "f1 = f1_score(vlabels, voutputs.argmax(axis=1), average='macro')\n",
    "\n",
    "print('Precission: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1_Macro: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final save for model & weights\n",
    "torch.save(model.state_dict(), 'final_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Model Experiment"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 17024,
     "sourceId": 20541,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 17025,
     "sourceId": 20542,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
